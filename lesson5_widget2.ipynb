{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similar_word_rankings(a, n=100):\n",
    "    sims = model.most_similar(a, topn = n)\n",
    "    dic = dict(sims)\n",
    "    similar_words = {k: v for k, v in dic.items() if not k.startswith(\"wiki\")}\n",
    "    similar_words = {k: similar_words[k] for k in list(similar_words)[:n]}\n",
    "    return similar_words\n",
    "\n",
    "def word_vectorizer(words):\n",
    "    \n",
    "    word_vecs = []\n",
    "    \n",
    "    for w in words:\n",
    "        v = model.wv[w]\n",
    "        word_vecs.append(v)\n",
    "        \n",
    "    vec = np.sum(word_vecs, axis = 0)\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def PCA_reduction(word_vec, dims = 2):\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(word_vec)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def sim_matrix(sims):\n",
    "\n",
    "    vecs = np.zeros((len(sims), 300))\n",
    "    i = 0\n",
    "    for k, v in sims.items():\n",
    "        vec = word_vectorizer([k])\n",
    "        vecs[i, :] = vec\n",
    "        i = i+1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#words should be an input\n",
    "words = ['STAR_WARS', 'Islam', 'dog']\n",
    "vocab = []\n",
    "mats = []\n",
    "for w in words:\n",
    "    sims = similar_word_rankings(w, 10)\n",
    "    for k, v in sims.items():\n",
    "        vocab.append(k)\n",
    "    sm = sim_matrix(sims)\n",
    "    mats.append(sm)\n",
    "\n",
    "\n",
    "final_mat = np.vstack((m for m in mats))\n",
    "\n",
    "result = PCA_reduction(final_mat)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10), dpi = 80)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(result[:, 0], result[:, 1])\n",
    "for i, word in enumerate(vocab):\n",
    "    ax.annotate(' '.join(word.split('_')), xy=(result[i, 0], result[i, 1]))\n",
    "    \n",
    "ax.set_xlim(-3, 3, 0.25)\n",
    "ax.set_xlim(-3, 3, 0.25)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
